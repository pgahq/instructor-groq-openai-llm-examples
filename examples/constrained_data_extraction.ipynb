{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChQ4YaZHvYbR"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Repo: https://github.com/pgahq/instructor-groq-openai-llm-examples\n",
        "\n",
        "This notebook shows how to use Instructor to extract structured info from unstructured text where the responses are constrained by an enumerated list. Instructor handles [Enum and Literal](https://jxnl.github.io/instructor/concepts/enums/) differently. Literal seems simpler.\n",
        "\n",
        "Note: this notebook assumes you're using Google Colab. You can safely edit / play here. Or go to `File` -> `Save a copy in Google Drive` to make your own version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7j-wjRULjwc4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install instructor groq openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA_GryIio4JN"
      },
      "source": [
        "On the left, click the key and set two secrets with your keys. Be sure to enable \"Notebook access\" for them. This is how Google Colab works...you're not sharing your keys with anyone.\n",
        "\n",
        "OPENAI_API_KEY\n",
        "\n",
        "GROQ_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import instructor\n",
        "import openai\n",
        "import groq\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional, List, Literal\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ['OPENAI_API_KEY'] = '' or userdata.get('OPENAI_API_KEY') # or put your key in the '' on this line\n",
        "    os.environ['GROQ_API_KEY'] = '' or userdata.get('GROQ_API_KEY')\n",
        "except Exception as e:\n",
        "    # print(e)\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9Om0C2YmGGj",
        "outputId": "1620461d-c5b3-4e49-a2fd-ca3f53ca9dd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"business_type\": \"dining establishment\",\n",
            "    \"sentiment\": \"good vibes\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "inference_provider = \"openai\"   # \"openai\" or \"groq\"\n",
        "client = instructor.from_openai(openai.OpenAI()) if inference_provider == \"openai\" else instructor.from_groq(groq.Groq())\n",
        "\n",
        "class Review(BaseModel):\n",
        "    business_type: Literal[\"dining establishment\", \"service business\", \"hotel\", \"other\"] = Field(description=\"Type of business.\")\n",
        "    sentiment: Literal[\"good vibes\", \"ok-ish\", \"not incredible\"] = Field(description=\"Sentiment of the review.\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"llama3-70b-8192\" if inference_provider == \"groq\" else \"gpt-4o\",\n",
        "    response_model=Review, # this is Instructor at work!\n",
        "    temperature=0.0,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"This place has amazing biscuits!\"}]    # intentionally vague so the LLM will need to infer the business type\n",
        "    # messages=[{\"role\": \"user\", \"content\": \"This place has amazing showers!\"}] \n",
        "    # messages=[{\"role\": \"user\", \"content\": \"This place has amazing appointment scheduling / reminders!\"}] \n",
        "    )\n",
        "\n",
        "print(response.model_dump_json(indent=4))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
