{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChQ4YaZHvYbR"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Repo: https://github.com/pgahq/instructor-groq-openai-llm-examples\n",
        "\n",
        "This notebook shows how to use Instructor to extract data and then validate the result. It will feed a text description of any validation issues back to the LLM (up to the specified number of retries) so it can correct its own response.\n",
        "\n",
        "Note: this notebook assumes you're using Google Colab. You can safely edit / play here. Or go to `File` -> `Save a copy in Google Drive` to make your own version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7j-wjRULjwc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet instructor groq openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA_GryIio4JN"
      },
      "source": [
        "On the left, click the key and set two secrets with your keys. Be sure to enable \"Notebook access\" for them. This is how Google Colab works...you're not sharing your keys with anyone.\n",
        "\n",
        "OPENAI_API_KEY - get a key from https://platform.openai.com/api-keys\n",
        "\n",
        "GROQ_API_KEY - get a key from https://console.groq.com/keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M9Om0C2YmGGj"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import groq\n",
        "import instructor\n",
        "from pydantic import BaseModel, Field\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ['OPENAI_API_KEY'] = '' or userdata.get('OPENAI_API_KEY') # or put your key in the '' on this line\n",
        "    os.environ['GROQ_API_KEY'] = '' or userdata.get('GROQ_API_KEY')\n",
        "except Exception as e:\n",
        "    # print(e)\n",
        "    pass\n",
        "\n",
        "if not os.environ.get('OPENAI_API_KEY') or not os.environ.get('GROQ_API_KEY'):\n",
        "    raise ValueError(\"Both OPENAI_API_KEY and GROQ_API_KEY environment variables must be set and non-empty. Read the text in the notebook (above this block) for more info.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2xtRfmD6pgH"
      },
      "source": [
        "Now to the cool stuff..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50rSTdEq6nr6",
        "outputId": "5c03b613-4efa-4580-e02b-3ed509ad0ec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90mValidating: Eric\u001b[0m\n",
            "\u001b[90mError: each character must be uppercase.\u001b[0m\n",
            "\u001b[90mValidating: ERIC\u001b[0m\n",
            "\u001b[90mSuccess\u001b[0m\n",
            "\n",
            "Final result:  ERIC\n"
          ]
        }
      ],
      "source": [
        "inference_provider = \"openai\"   # \"openai\" or \"groq\"\n",
        "client = instructor.from_openai(openai.OpenAI()) if inference_provider == \"openai\" else instructor.from_groq(groq.Groq())\n",
        "\n",
        "class UserDetail(BaseModel):\n",
        "    \"\"\"\n",
        "    Details about the user\n",
        "    \"\"\"\n",
        "    name: str = Field(description=\"First name (only) of the user.\")\n",
        "    age: int = Field(description=\"Age of the user.\")\n",
        "\n",
        "    @field_validator(\"name\")\n",
        "    @classmethod\n",
        "    def validate(cls, v):\n",
        "        print(f\"\\033[90mValidating: {v}\\033[0m\")  # Grey text output\n",
        "        if not v.isupper():\n",
        "            error_message = \"each character must be uppercase.\" # this is the text that gets fed back to the LLM on the retry\n",
        "            print(f\"\\033[90mError: {error_message}\\033[0m\")  # Grey text output\n",
        "            raise ValueError(error_message)\n",
        "        print(f\"\\033[90mSuccess\\033[0m\")  # Grey text output\n",
        "        return v\n",
        "\n",
        "model = client.chat.completions.create(\n",
        "    model=\"llama-3.1-70b-versatile\" if inference_provider == \"groq\" else \"gpt-4o-mini\",\n",
        "    response_model=UserDetail,\n",
        "    max_retries=4,\n",
        "    temperature=0,  # don't be creative\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Eric Smith is 12 years old.\"}]\n",
        "    )\n",
        "\n",
        "print(\"\\nFinal result: \", model.name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
