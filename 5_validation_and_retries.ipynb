{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChQ4YaZHvYbR"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook shows how to use Instructor to extract data and then validate the result. It will feed a text description of any validation issues back to the LLM (up to the specified number of retries) so it can correct its own response.\n",
        "\n",
        "Note: this notebook assumes you're using Google Colab. You can safely edit / play here. Or go to `File` -> `Save a copy in Google Drive` to make your own version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7j-wjRULjwc4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install instructor groq openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA_GryIio4JN"
      },
      "source": [
        "On the left, click the key and set two secrets with your keys. Be sure to enable \"Notebook access\" for them. This is how Google Colab works...you're not sharing your keys with anyone.\n",
        "\n",
        "OPENAI_API_KEY\n",
        "\n",
        "GROQ_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M9Om0C2YmGGj"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minstructor\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m userdata\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      8\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m userdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# or put your key in the '' on this line\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import groq\n",
        "import instructor\n",
        "from pydantic import BaseModel, Field\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '' or userdata.get('OPENAI_API_KEY') # or put your key in the '' on this line\n",
        "os.environ['GROQ_API_KEY'] = '' or userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2xtRfmD6pgH"
      },
      "source": [
        "Now to the cool stuff..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50rSTdEq6nr6",
        "outputId": "5c03b613-4efa-4580-e02b-3ed509ad0ec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90mValidating: Eric\u001b[0m\n",
            "\u001b[90mError: each character must be uppercase.\u001b[0m\n",
            "\u001b[90mValidating: ERIC\u001b[0m\n",
            "\u001b[90mSuccess\u001b[0m\n",
            "\n",
            "Final result:  ERIC\n"
          ]
        }
      ],
      "source": [
        "import instructor\n",
        "import openai\n",
        "import groq\n",
        "from pydantic import BaseModel, Field, field_validator\n",
        "\n",
        "inference_provider = \"openai\"   # \"openai\" or \"groq\"\n",
        "client = instructor.from_openai(openai.OpenAI()) if inference_provider == \"openai\" else instructor.from_groq(groq.Groq())\n",
        "\n",
        "class UserDetail(BaseModel):\n",
        "    \"\"\"\n",
        "    Details about the user\n",
        "    \"\"\"\n",
        "    name: str = Field(description=\"First name (only) of the user.\")\n",
        "    age: int = Field(description=\"Age of the user.\")\n",
        "\n",
        "    @field_validator(\"name\")\n",
        "    @classmethod\n",
        "    def validate(cls, v):\n",
        "        print(f\"\\033[90mValidating: {v}\\033[0m\")  # Grey text output\n",
        "        if not v.isupper():\n",
        "            error_message = \"each character must be uppercase.\" # this is the text that gets fed back to the LLM on the retry\n",
        "            print(f\"\\033[90mError: {error_message}\\033[0m\")  # Grey text output\n",
        "            raise ValueError(error_message)\n",
        "        print(f\"\\033[90mSuccess\\033[0m\")  # Grey text output\n",
        "        return v\n",
        "\n",
        "model = client.chat.completions.create(\n",
        "    model=\"llama3-70b-8192\" if inference_provider == \"groq\" else \"gpt-4-turbo\",\n",
        "    response_model=UserDetail,\n",
        "    max_retries=4,\n",
        "    temperature=0,  # don't be creative\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Eric Smith is 12 years old.\"}]\n",
        "    )\n",
        "\n",
        "print(\"\\nFinal result: \", model.name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
